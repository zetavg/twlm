{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPz3gUOjlkK1O9K1z/eBBK/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zetavg/twlm/blob/main/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TWLM Demo\n",
        "\n",
        "ç”±ä¸Šæ–¹é¸å–®é¸æ“‡ã€Œ**åŸ·è¡Œéšæ®µ**ã€>ã€Œ**å…¨éƒ¨åŸ·è¡Œ**ã€(\"Runtime\" > \"Run all\") ä¾†å•Ÿå‹•ã€‚\n",
        "\n",
        "éç¨‹ä¸­æœƒè‡ªå‹•ä¸‹è¼‰éœ€è¦çš„æ¨¡å‹ï¼Œåˆæ¬¡åŸ·è¡Œåˆ°å¯ä»¥ä½¿ç”¨å¤§æ¦‚éœ€è¦äº”åˆ°å…«åˆ†é˜ã€‚\n",
        "\n",
        "åœ¨ã€Œ**4. å•Ÿå‹• UI**ã€çš„æ­¥é©Ÿæœƒè¼¸å‡ºä¸€å€‹ç¶²å€ï¼Œé»æ“Šè©²ç¶²å€å¯ä»¥é–‹å•Ÿ UIã€‚"
      ],
      "metadata": {
        "id": "AKwaGTqauVVq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD9jYjmcrTF8"
      },
      "outputs": [],
      "source": [
        "#@title 1. å®‰è£\n",
        "#@markdown ç¬¬ä¸€æ¬¡åŸ·è¡Œæ™‚ï¼Œé€™å€‹æ­¥é©Ÿéœ€è¦èŠ±è²»å¤§ç´„ä¸€åˆ†é˜ã€‚\n",
        "\n",
        "!rm -rf llm_tuner\n",
        "!git clone -b twlm-demo https://github.com/zetavg/LLaMA-LoRA-Tuner.git llm_tuner\n",
        "!pip install -r llm_tuner/requirements.txt\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. ä¸€äº›è¨­å®š\n",
        "#@markdown å¦‚æœæœ‰ Colab Pro å¯ä»¥ç”¨ï¼ŒGPU é¸ V100 æˆ– A100 çš„è©±ï¼Œå¯ä»¥æŠŠ `Config.default_load_in_8bit` æ”¹æˆ `False`ï¼Œæ¨¡å‹çš„é€Ÿåº¦æœƒæ›´å¿«ã€è¼¸å‡ºå“è³ªæœƒæ›´å¥½ã€‚\n",
        "\n",
        "from llm_tuner.llm_tuner.config import Config, process_config\n",
        "\n",
        "Config.demo_mode = True\n",
        "\n",
        "Config.default_load_in_8bit = True\n",
        "Config.default_device_map = {'': 0}\n",
        "# Config.default_device_map = 'auto'\n",
        "\n",
        "Config.ui_show_starter_tooltips = False\n",
        "Config.ui_inference_open_options_by_default = False\n",
        "Config.ui_chat_reminder_message = \"èªè¨€æ¨¡å‹å¯èƒ½æœƒç”¢ç”Ÿä¸æ­£ç¢ºçš„è³‡è¨Šã€‚å› è¨“ç·´æˆæœ¬èˆ‡å…è²»ç‰ˆ Colab è¨˜æ†¶é«”é™åˆ¶ï¼Œæ¨¡å‹ç›®å‰å°é•·ä¸²å°è©±çš„è¡¨ç¾ä¸æ˜¯å¾ˆå¥½ï¼Œåœ¨å¤šè¼ªå°è©±å¾Œå¯èƒ½æœƒé–‹å§‹å›æ‡‰é‡è¤‡çš„å…§å®¹ã€‚å¦‚æœå°å›æ‡‰ä¸æ»¿æ„ï¼Œå¯ä»¥å˜—è©¦æŒ‰ä¸‹ã€ŒRegenerate Responseã€ã€‚<br/>å°è©±ç´€éŒ„åªæœƒä¿å­˜åœ¨ç€è¦½å™¨ä¸­ï¼Œé—œé–‰ Colab æ™‚å°±æœƒæ¶ˆå¤±ï¼Œè‹¥æœ‰éœ€è¦è«‹è‡ªè¡Œå‚™ä»½ (å±•é–‹å·¦ä¸‹è§’ã€ŒRaw Dataã€æŸ¥çœ‹ç›¸é—œè³‡è¨Š)ã€‚ä¸‹æ–¹ã€ŒExamplesã€æœ‰ä¸€äº›è¨Šæ¯ç¯„æœ¬å¯ä»¥é¸æ“‡ã€‚\"\n",
        "Config.ui_model_and_prompt_template_select_notice = \"åœ¨ Colab ä¸Šä½¿ç”¨éé è¨­çš„æ¨¡å‹æ™‚ï¼Œéœ€è¦èŠ±è²»å¤§ç´„äº”åˆ†é˜ä¾†ä¸‹è¼‰æ¨¡å‹ (åˆæ¬¡ä½¿ç”¨æ™‚)ï¼Œä»¥åŠå¤§ç´„ä¸€åˆ†é˜è¼‰å…¥æ¨¡å‹ (æ¯æ¬¡åˆ‡æ›)ï¼Œè«‹è€å¿ƒç­‰å€™ã€‚èªè¨€æ¨¡å‹èˆ‡å°è©±å‡åœ¨\"\n",
        "Config.ui_features = ['chat', 'inference', 'tools']\n",
        "\n",
        "Config.ui_title = \"[Colab] TWLM Demo\"\n",
        "Config.ui_subtitle = \"\"\n",
        "Config.ui_emoji = \"ğŸ¦™ğŸ›ï¸\"\n",
        "\n",
        "Config.default_generation_config = {\n",
        "    'temperature': 1,\n",
        "    'top_k': 40,\n",
        "    'top_p': 0.2,\n",
        "    'num_beams': 2,\n",
        "    'repetition_penalty': 2.4,\n",
        "    'max_new_tokens': 800,\n",
        "}\n",
        "Config.default_generation_stop_sequence = \"### Human:\""
      ],
      "metadata": {
        "id": "0wDKbBttsW7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. åˆå§‹åŒ–\n",
        "#@markdown ç¬¬ä¸€æ¬¡åŸ·è¡Œæ™‚ï¼Œé€™å€‹æ­¥é©Ÿéœ€è¦èŠ±è²»å¤§ç´„äº”åˆ†é˜ä¸‹è¼‰æ¨¡å‹ã€‚ä¹‹å¾Œï¼Œéœ€è¦èŠ±è²»ç´„ä¸€åˆ†åŠé˜ä¾†è¼‰å…¥æ¨¡å‹ã€‚<br /><br />å¦‚æœå› ç‚ºç”¨ç›¡è¨˜æ†¶é«”è€Œå¤±æ•—ï¼Œå¯ä»¥è©¦è‘—å†åŸ·è¡Œä¸€æ¬¡ã€‚\n",
        "\n",
        "from llm_tuner.llm_tuner.initialization import initialize\n",
        "initialize()"
      ],
      "metadata": {
        "id": "A76sH3tYtgT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. å•Ÿå‹• UI { display-mode: \"form\" }\n",
        "#@markdown åŸ·è¡Œæ­¤å€å¡Šæœƒè¼¸å‡ºé¡ä¼¼ <br />`Running on public URL: https://xxxx.gradio.live` <br/>çš„æ–‡å­—ï¼Œé»æ“Šå…¶ä¸­ `https://xxxx.gradio.live` çš„ç¶²å€å³å¯é–‹å•Ÿ UIã€‚\n",
        "#@markdown ï¼ˆé›–ç„¶ç›´æ¥åœ¨åº•ä¸‹ä½¿ç”¨ä¹Ÿè¡Œï¼Œä½†é–‹æ–°çš„è¦–çª—ä¾†ç”¨æ¯”è¼ƒå¥½ç”¨ï¼‰\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "from llm_tuner.llm_tuner.ui import (\n",
        "    main_page, get_page_title, get_css_styles\n",
        ")\n",
        "\n",
        "with gr.Blocks(title=get_page_title(), css=get_css_styles()) as demo:\n",
        "    main_page()\n",
        "\n",
        "demo.queue(concurrency_count=1).launch(share=True, debug=True, server_name=\"127.0.0.1\")"
      ],
      "metadata": {
        "id": "KO21gqyct_YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from transformers import AutoModelForCausalLM\n",
        "# m = AutoModelForCausalLM.from_pretrained(\n",
        "#     'zh-tw-llm-dv/tw-pythia-6.9b-chat-v0_2-s2',\n",
        "#     torch_dtype=torch.float16,\n",
        "#     load_in_8bit=True,\n",
        "#     device_map={'': 0},\n",
        "# )"
      ],
      "metadata": {
        "id": "FNliRc8OG_jS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}